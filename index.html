<!DOCTYPE html>
<html lang="en">
<head>

    <!-- Basic Page Needs
    ================================================== -->
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>Wei Lai's homepage</title>

    <meta name="description" content="">
    <meta name="author" content="">
    <meta name="keywords" content="">

    <!-- Mobile Specific Metas
    ================================================== -->
    <meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0">
    <meta name="apple-mobile-web-app-capable" content="yes" />

    <!-- Fonts -->
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,600,700" rel="stylesheet">

    <!-- Favicon
    ================================================== -->
    <link rel="apple-touch-icon" sizes="180x180" href="assets/img/ear-wav.png">
    <link rel="icon" type="img/png" sizes="16x16" href="assets/img/ear-wav.png">

    <!-- Stylesheets
    ================================================== -->
    <!-- Bootstrap core CSS -->
    <link href="assets/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="assets/css/style.css" rel="stylesheet">
    <link href="assets/css/responsive.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>
<body>
    <header id="masthead" class="site-header" data-anchor-target=".row" data-top="background: rgba(255,255,255,0); padding: 30px 0; box-shadow: 0px 0px 20px 6px rgba(0, 0, 0, 0);" data-top-bottom="background: rgba(255,255,255,1); padding: 10px 0; box-shadow: 0px 0px 20px 6px rgba(0, 0, 0, 0.2);">
        <nav id="primary-navigation" class="site-navigation">
            <div class="container">
                <div class="navbar-header page-scroll">
                    <button type="button" class="navbar-toggle collapsed" data-target="#portfolio-perfect-collapse" aria-expanded="false" >
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    
                    <a href="#hero" class="site-logo"><img src="assets/img/logo.png" alt="logo"></a>

                </div><!-- /.navbar-header -->

                <div class="main-menu" id="portfolio-perfect-collapse">

                    <ul class="nav navbar-nav navbar-right">
                        <li class="page-scroll"><a href="#service">Home</a></li>
                        <li class="page-scroll"><a href="#portfolio">Research</a></li>
                        <li class="page-scroll"><a href="#publication">Publication</a></li>
                        <li class="page-scroll"><a href="#presentation">Presentation</a></li>
                        <li class="page-scroll"><a href="#teaching">Teaching</a></li>
                        <li class="page-scroll"><a href="#resources">Resources</a></li>
                    </ul><!-- /.navbar-nav -->

                </div><!-- /.navbar-collapse -->

            </div>
        </nav><!-- /.primary-navigation -->
    </header><!-- /#header -->

    <main id="main" class="site-main">
        <section id="service" class="site-section section-services overlay text-center">
            <div class="container">
                <div class="row">
                    <div class="col-md-12">
                       <h3 style=" color:#68829E" >Welcome</h3>
                        <img src="assets/img/lines.svg" class="img-lines" alt="lines">
                          <div id="content" >
                        
                            <img src="assets/img/profile_smile.jpg" width="30%" align="left" style="max-width:18em; margin: 10px 30px 10px 10px;"/>

                            <p align="left" > Hi! I am Wei Lai (赖玮). I am currently a postdoctoral research scholar in the <a style="color:#063852" href="https://www.vanderbilt.edu/psychological_sciences/">Department of Psychology and Human Development</a> at <a style="color:#063852" href="https://www.vanderbilt.edu/"> Vanderbilt University</a>. My supervisor is  <a style="color:#063852"  href="https://www.vanderbilt.edu/psychological_sciences/bio/duane-watson" >Duane Watson</a>. Starting from December 2022, I will become a language engineer at Amazon Web Services.</p>

                            <p  align="left" > Before coming to Vanderbilt, I received my Ph.D. in Linguistics in May 2021 from the <a style="color:#063852" class="social-links" href="https://www.upenn.edu"  >University of Pennsylvania</a>. The title of my doctoral dissertation is <a style="color:#063852" href="https://www.proquest.com/openview/1d43bc09b53dd6c406aa2f7e5dbb8a77/1?pq-origsite=gscholar&cbl=18750&diss=y">"The online adjustment of speaker-specific phonetic beliefs in multi-speaker speech perception"</a>. My dissertation advisor is <a style="color:#063852"  href="http://www.meredithtamminga.com" >Meredith Tamminga</a>. </p>

                             <p  align="left" > My research interests lie in speech science, sociophonetics, and more recently, social cognitive mechanisms involved in the processing of sociolinguistic variants. I also have a long-lasting research interest in the production and perception of lexical tones and speech prosody. </p>  
                           
                            <a href="https://github.com/weilaiPhonetics/CV/raw/main/CV_WeiLai_2022.pdf" style="background-color: #1e1f26; color:#FCFDFE"  class="btn btn-fill" target="_blank" download>Download my cv</a></p>
                          </div>
                    </div>
                </div>
            </div>
        </section><!-- /.secton-services -->


 <section id="portfolio" class="site-section section-portfolio">
    <div class="container" align="center">
       <h3 style=" color:#68829E" class="text-center">Research</h3>
        <img src="assets/img/lines.svg" class="img-lines" alt="lines">

            <p  align="left">Generally, I am interested in the acoustic and perceptual aspects of speech. Most of my recent studies focus on the problem of <i>variability</i> of speech, trying to answer (a) how speakers encode linguistic information in the acoustic space in different ways as a function of contextually flexible factors, based on acoustic measurements of lab-elicited and corpus-collected speech; and (b) how listeners take the social-contextual variabilities into account to uncover linguistically meaningful units from raw speech signals in their perception and processing behaviors. Besides, I have a long-lasting interest in <i>suprasegmental</i> aspects of speech, e.g., pitch, timing, intensity, voice quality, etc. My studies in this line focus on lexical tones and speech prosody.  </p>

            <p  align="left">The main topics of my research work are listed as follows: </p>

              
            <h4 align="left" style="font-family: sans-serif; color:#063852; font-size: 20px; margin-top: 30px" id="social"> Integration of social-indexical cues in linguistic processing</h4>
             <div class="row">
             <p  align="left"> <img src="assets/img/processing.png" width="95%" align="left" style="max-width:11em; margin: 30px 30px 10px 10px;"/>In spoken languages, linguistic meanings and social-indexical information of a talker are closely interwoven. Listeners not only find an interlocutor's speech more or less intelligible depending on their opinions about the speaker, but also hear different phoneme on the same piece of ambiguous signal depending on the perceived identity of the speaker. Studies in this vein extend to the field of social cognition and investigate questions such as how socio-indexical information is represented in listeners' brains and associated with linguistic variants, and how listeners consciously or unconsciously make use of these associations to form expectations, understandings (or misunderstandings) towards their interlocutors. </p></div>

             
             <h4 align="left" id="flexibility" style="font-family: sans-serif; color:#063852; font-size: 20px; margin-top: 30px">Flexibility of speech perception: compensation, adaptation, generalization</h4>
             <div class="row">
             <p  align="left"> <img  src="assets/img/perception.png" width="95%" align="left" style="max-width:11em; margin: 10px 30px 10px 10px;"/> The acoustic realization of a particular phoneme may vary massively as a function of the linguistic environment, acoustic surrounding, social context, style, speech rate, talker identity, lexical properties, among others. Accordingly, listeners' speech perception mechanisms are very sophisticated and flexible. Listeners can not only adjust their phonemic boundaries perceived from ambiguous signals according to coarticulatory/ phonotactic/ lexical/ semantic contexts; they can also learn and memorize idiosyncratic acoustic distributions of phonemes for different talkers, and generalize the distribution to new talkers. This line of research investigates the linguistic and social structures that shape listeners' perceptual compensation, adaptation, and generalization.</p></div>
     
            <h4 align="left" style="font-family: sans-serif; color:#063852; font-size: 20px ; margin-top: 30px">Acoustics and perception of lexical tone variation</h4>
            <div class="row">
             <p  align="left"> <img src="assets/img/tone.png" width="95%" align="left" id="tone" style="max-width:11em; margin: 10px 30px 10px 10px;"/> While much attention has been attributed to the acoustic measurements of tonal contrast and the establishment of tone typology, fewer attempts are made to explore tone variability. Different from segment, tone is mainly realized by <i>F<sub>0</sub></i>, which is more heavily dependent on the talkers' sex and vocal state, and less on the oral track. Some of my recent studies start to investigate how talker sex, vocal effort, and tonal contrast are simultaneously encoded in the <i>F<sub>0</sub></i> space, and how listeners manage to resolve the ambiguity caused by acoustic overlap. I also care about the variability of tonal shapes as a function of lexical and prosodic structures, and methods to modle this variability. Besides, I have always wanted to look at the diachronic change of neutral tones by lexical items. </p></div>
                
            
            <h4 align="left" id="prosody" style="font-family: sans-serif;color:#063852; font-size: 20px; margin-top: 30px">Measurement and Perception of intonation and prosody</h4>
              <div class="row">
              <p  align="left">  <img src="assets/img/intonation.png" width="99%" align="left" style="max-width:11em; margin: 10px 30px 10px 10px;"/> I am interested in the typology, phonologization, acoustics, perception, and modeling of intonation and prosody. My research on prosody is twofold. One aspect is the measurement of prosodic parameters, with the hope that reliable parameters will enable us to reliably visualize the underlying structure of prosody, and to separate them from extrinsic <i>F<sub>0</sub></i> byproducts unrelated to the core properties of intonation. I also did some tentative work is an important but relatively understudied field. The project aims to use perception as a window to probe the linguistically meaningful prosody patterns, which attribute contrasting interpretations for a speech stretch.  </p></div>
            </div></div></div>
      </div>
    </div>
  </section>

 <section id="publication"  class="site-section section-services overlay text-center">
    <div align="center" class="container">
      <h3 style=" color:#68829E"  class="text-center">Publications</h3>
        <img  src="assets/img/lines.svg" class="img-lines" alt="lines">
        <div style="margin-left:0px;margin-right:0px">
          <h4 align="left" style="font-family: sans-serif; color:#063852; font-size: 20px" >Journal Papers</h4><br>
          <ul>
        <li align="left" ><span style="color:#063852">Wei Lai</span>, Aini Li (2022). Integrating the phonological and phonetic aspects of Mandarin Tone 3 sandhi in auditory sentence disambiguation. <i>Laboratory Phonology</i>, 13 (1), pp. 1-31. <a href="https://www.journal-labphon.org/article/id/6416/" style="color:#002366"> [paper]</a> <a style="color:#002366" href="https://osf.io/ubgpw/">[data]</a></li>

        <li align="left" ><span style="color:#063852">Wei Lai</span>, Lacey Wade and Meredith Tamminga (2022). Individual differences in simultaneous perceptual compensation for coarticulatory and lexical cues. <i>Linguistics Vanguard</i>. 2022 May 5. <a href="https://www.meredithtamminga.com/pdf/2022_LaiWadeTamminga.pdf" style="color:#002366">[paper]</a> <a style="color:#002366" href="https://osf.io/kefn4/">[data]</a></li>
      
        <li align="left" >Lacey Wade, <span style="color:#063852">Wei Lai</span> and Meredith Tamminga (2021). The reliability of individual differences in VOT imitation. <i>Language and Speech</i>, 64 (3), pp. 576-593. <a href="https://journals.sagepub.com/doi/abs/10.1177/0023830920947769"  style="color:#002366">[paper]</a></li>
         
        <li align="left" ><span style="color:#063852">Wei Lai</span>, Jianjing Kuang (2020). The effect of speaker gender on Cantonese tone perception. <i>The Journal of the Acoustical Society of America</i>, 147 (6), pp. 4119-4132. <a href="https://asa.scitation.org/doi/abs/10.1121/10.0001411" style="color:#002366" >[paper]</a></li>

        <li align="left" ><span style="color:#063852">Wei Lai</span>, Peter Racz, Gareth Roberts (2020). Experience with a linguistic variant affects the acquisition of its sociolinguistic meaning: An alien-language-learning experiment. <i>Cognitive Science</i>. 44 (4), e12832. <a href="https://ling.auf.net/lingbuzz/005049"  style="color:#002366">[paper]</a> <a style="color:#002366" href="https://osf.io/vbqdy/">[data]</a></li>

        <li align="left" >Meredith Tamminga, Robert Wilder, <span style="color:#063852">Wei Lai</span> and Lacey Wade (2020). Perceptual learning, talker specificity and sound change. <i> Papers in Historical Phonology</i>, 5, 90-122. <a href="http://journals.ed.ac.uk/pihph/article/view/4439"  style="color:#002366">[paper]</a></li>
          
         <li align="left" >Jiahong Yuan, <span style="color:#063852">Wei Lai</span>, Chris Cieri and Mark Liberman (2018). Using Forced Alignment for Phonetics Research. <i>Chinese Language Resources and Processing:Text, Speech and Language Technology. Springer. </i> <a href="http://languagelog.ldc.upenn.edu/myl/ForcedAlignment_Final_edited.pdf"  style="color:#002366">[paper]</a></li>
          
         <li align="left" >Ya Li, Jianhua Tao, <span style="color:#063852">Wei Lai</span>, and Xiaoying Xu (2017). Quantitative intonation modeling of interrogative sentences for Mandarin speech synthesis. <i>Speech Communication</i>, 89, 92-102. <a href="https://www.researchgate.net/profile/Wei_Lai17/publication/315534662_Quantitative_intonation_modeling_of_interrogative_sentences_for_Mandarin_Speech_Synthesis/links/5bd37833a6fdcc3a8da91efc/Quantitative-intonation-modeling-of-interrogative-sentences-for-Mandarin-Speech-Synthesis.pdf"  style="color:#002366">[paper]</a></li>
        
        <li align="left" >Ya Li, Jianhua Tao, Keikichi Hirose, Xiaoying Xu and <span style="color:#063852">Wei Lai</span> (2015). Hierarchical stress modeling and generation in mandarin for expressive Text-to-Speech. <i>Speech Communication</i>, 72, 59-73. <a href="http://www.speakit.cn/Group/file/2015_StressExpressiveTTS_SpeechCommun15_SCI.pdf"  style="color:#002366">[paper]</a></li></ul><br>
        
        <h4 align="left" style="font-family: sans-serif; color:#063852; font-size: 20px" >Submitted Manuscripts</h4><br>
          <ul>
            <li align="left" >Esteban Buz, Nichole Dwyer, <span style="color:#063852">Wei Lai</span>, Duane Watson, and Rene Gifford. Integration of timing and spectral cues to voicing categorization: listeners with normal hearing and bimodal hearing configurations. <i>Under review </i>.</li>
          </ul><br>
          <h4 align="left" style="font-family: sans-serif; color:#063852; font-size: 20px" >Conference Papers</h4><br>
          <ul>
            <li align="left" ><span style="color:#063852">Wei Lai</span>, Aini Li (2022). The perceptual generalization of normalized cue distributions across speakers. In <i>Proc. of CogSci 2022</i> (pp. 1138-1144). <a href="https://escholarship.org/content/qt363410t3/qt363410t3.pdf"   style="color:#002366">[paper]</a></li>

            <li align="left" >Aini Li, <span style="color:#063852">Wei Lai</span>, and Jianjing Kuang (2022). How do listeners identify creak? The case of Mandarin. In <i>Proc. of Speech Prosody 2022</i>  (pp. 480-484). <a href="https://www.researchgate.net/profile/Wei-Lai/publication/360794524_How_do_listeners_identify_creak_The_effects_of_pitch_range_prosodic_position_and_creak_locality_in_Mandarin/links/629c3d1c55273755ebd35d40/How-do-listeners-identify-creak-The-effects-of-pitch-range-prosodic-position-and-creak-locality-in-Mandarin.pdf"   style="color:#002366">[paper]</a></li>

            <li align="left" ><span style="color:#063852">Wei Lai</span>, Aini Li (2020). Integrating the application and realization of Mandarin 3rd tone sandhi in the resolution of sentence ambiguity. In <i>Proc. of Interspeech 2020</i> (pp. 1918-1922). <a href="http://www.interspeech2020.org/uploadfile/pdf/Wed-1-1-4.pdf" style="color:#002366">[paper]</a></li>

            <li align="left" ><span style="color:#063852">Wei Lai</span>, Mark Liberman and Qianxin He (2019). Compensation for <i>F<sub>0</sub></i> variation with vocal effort and vowel height in Cantonese tone perception. In <i>Proc. ICPhS 2019.  </i>  (pp. 1972-1976). <a href="https://assta.org/proceedings/ICPhS2019Microsite/pdf/full-paper_488.pdf"   style="color:#002366">[paper]</a></li>

            <li align="left" ><span style="color:#063852">Wei Lai</span>, Peter Racz and Gareth Roberts (2019). Unexpectedness makes a sociolinguistic variant easier to learn: An alien-language-learning experiment. In <i>Proc. CogSci 2019. </i> (pp. 604-610). <a href="https://cogsci.mindmodeling.org/2019/papers/0122/0122.pdf"   style="color:#002366">[paper]</a></li>

            <li align="left" ><span style="color:#063852">Wei Lai</span> (2018). Voice Gender Effect on Tone Categorization and Pitch Perception. In <i>Proc. TAL2018, Sixth International Symposium on Tonal Aspects of Languages.</i> (pp. 103-107). <a href="http://public.beuth-hochschule.de/~mixdorff/tal2018/180619_oral_session_6/TAL_2018_paper_43.pdf"   style="color:#002366">[paper]</a></li>

            <li align="left" ><span style="color:#063852">Wei Lai</span> (2017). Auditory-visual integration of talker gender in Cantonese tone perception. In <i>Proc. of Interspeech 2017</i>. (pp. 664-668). <a href="https://pdfs.semanticscholar.org/63b5/0026b773732607a9e243925ff796909ab0b9.pdf"   style="color:#002366">[paper]</a></li>

            <li align="left" ><span style="color:#063852">Wei Lai</span>, Mark Liberman, Jiahong Yuan and Xiaoying Xu (2016). Prosodic strength intrinsic to lexical items: A corpus study on tone reduction in Tone4+ Tone4 words in Mandarin Chinese. In Chinese Spoken Language Processing (ISCSLP), 10th International Symposium. (pp. 1-5). IEEE. <a href="https://www.researchgate.net/profile/Wei_Lai17/publication/309733979_Prosodic_Strength_Intrinsic_to_Lexical_Items_A_Corpus_Study_on_Tone_Reduction_in_Tone4Tone4_Words_in_Mandarin_Chinese/links/5bd3792492851c6b2791fbbe/Prosodic-Strength-Intrinsic-to-Lexical-Items-A-Corpus-Study-on-Tone-Reduction-in-Tone4-Tone4-Words-in-Mandarin-Chinese.pdf"   style="color:#002366">[paper]</a> </li>

            <li align="left" ><span style="color:#063852">Wei Lai</span>, Jiahong Yuan, Ya Li, Xiaoying Xu, and Mark Liberman (2016). The Rhythmic Constraint on Prosodic Boundaries in Mandarin Chinese Based on Corpora of Silent Reading and Speech Perception. In <i>Proc. of Interspeech 2016</i> (pp. 87-91). (best student paper award). <a href="https://www.isca-speech.org/archive/Interspeech_2016/pdfs/0607.PDF"   style="color:#002366">[paper]</a></li>

            <li align="left" ><span style="color:#063852">Wei Lai</span> and Laura Dilley (2016). Cross-linguistic generalization of the distal rate effect: Speech rate in context affects whether listeners hear a function word in Chinese Mandarin. In <i>Proceedings of Speech Prosody</i>  (Vol. 8, pp. 1124-1128). <a href="https://pdfs.semanticscholar.org/0ca9/0300252c39b450526ac97217057f7edb4362.pdf"  style="color:#002366">[paper]</a></li>

            <li align="left" ><span style="color:#063852">Wei Lai</span> and Jianjing Kuang (2016). Prosodic grouping in Chinese trisyllabic structules by multiple cues -- coarticulation, tone sandhi and consonant lenition. Tonal Aspects of Languages 2016, 157-161. <a href="https://pdfs.semanticscholar.org/87f4/3b25cb6fca2437ca4227df8424c6d5826e5f.pdf"   style="color:#002366">[paper]</a></li>

            <li align="left"  >Jiahong Yuan, Xiaoying Xu, <span style="color:#063852">Wei Lai</span> and Mark Liberman (2016). Pauses and pause fillers in Mandarin monologue speech: The effects of sex and proficiency. <i>Proceedings of Speech Prosody 2016</i>, 1167-1170. <a href="https://pdfs.semanticscholar.org/7f15/be1f4954ec9f9e7600264666bcae2119e5bb.pdf"   style="color:#002366">[paper]</a></li>

            <li align="left" >Jiahong Yuan, Xiaoying Xu, <span style="color:#063852">Wei Lai</span>, Weiping Ye, Xinru Zhao and Mark Liberman (2015). Sentence selection for automatic scoring of Mandarin proficiency. In <i>Proceedings of the Eighth SIGHAN Workshop on Chinese Language Processing</i> (pp. 21-25). <a href="https://pdfs.semanticscholar.org/634e/ce61f7da0e65f5ca14982f6cfcc75cf86caa.pdf"  style="color:#002366">[paper]</a></li>

            <li align="left"  ><span style="color:#063852">Wei Lai</span>, Xiaoying Xu, Ya Li, Che, H., Shanfeng Liu, and Jianhua Tao (2014). Phonological influences on the realization of final lowering: Evidence from dialogue Chinese Mandarin. In 17th Oriental Chapter of the International Committee for the Co-ordination and Standardization of Speech Databases and Assessment Techniques (pp. 1-6). IEEE. <a href="https://www.researchgate.net/profile/Wei_Lai17/publication/292971155_Phonological_influences_on_the_realization_of_final_lowering_evidence_from_dialogue_Chinese_Mandarin/links/56b2dfeb08ae795dd5c7d71b.pdf"  style="color:#002366">[paper]</a></li>

            <li align="left" ><span style="color:#063852">Wei Lai</span>, Ya Li, Che, H., Shanfeng Liu, Jianhua Tao, and Xiaoying Xu (2014). Final lowering effect in questions and statements of Chinese Mandarin based on a large-scale natulal dialogue corpus Analysis. <i>Proc. 7th Speech Prosody</i>, 653-657. <a href="https://www.researchgate.net/profile/Wei_Lai17/publication/287789609_Final_Lowering_Effect_in_Questions_and_Statements_of_Chinese_Mandarin_Based_on_a_Largescale_Natural_Dialogue_Corpus_Analysis/links/56b2e1e808ae795dd5c7d742/Final-Lowering-Effect-in-Questions-and-Statements-of-Chinese-Mandarin-Based-on-a-Largescale-Natural-Dialogue-Corpus-Analysis.pdf"   style="color:#002366">[paper]</span></a></li>

            <li align="left"  >Ya Li, Jianhua Tao, Keikichi Hirose, <span style="color:#063852">Wei Lai</span> and Xiaoying Xu (2014). Hierarchical stress generation with Fujisaki model in expressive speech synthesis. <i>Proc. 7th Speech Prosody</i>, 1032-1036. <a href="https://pdfs.semanticscholar.org/2010/823e8433cbdc692880e15e1ddc74dadbd8c7.pdf"  style="color:#002366">[paper]</a></li>
          </ul>
      </div>
    </div>
  </section>

 <section id="presentation" class="site-section section-services overlay text-center">
    <div class="container" align="center">
       <h3 style=" color:#68829E" class="text-center">Presentation</h3>
        <img src="assets/img/lines.svg" class="img-lines" alt="lines">

 <h4 align="left" id="flexibility" style="font-family: sans-serif;color:#063852; font-size: 20px; margin-top: 30px">2022</h4>
    <p> <ul>
        <li align="left" > <span style="color:#063852">Wei Lai</span> and Aini Li. The perceptual generalization of normalized cue distributions across
        speakers. The 44th Annual Meeting of the Cognitive Science Society. Toronto, Canada. (talk)</li>
        <li align="left" >Aini Li, <span style="color:#063852">Wei Lai</span>. A matched-guise study of Mandarin creaky voice. New Ways of Analyzing Variation (NWAV) 50. San Jose, CA. (talk)</li>
         <li align="left" > <span style="color:#063852">Wei Lai</span>, Sunghye Cho, Mark Liberman, Azia Knox, Alison Russel, Maggie Rose Pelella, Meredith Cola, Kimberly Tena, Juhi Pandy, Robert T. Schultz, and Julia Parish-Morris. Girls with Autism Speed up More in a Tongue Twister Task. Annual Meeting of the International Society for Autism Research (INSAR). Austin, Texas. (poster)</li> 
         <li align="left" > Sunghye Cho, Riccardo Fusaroli, Kimberly Tena, Azia Knox, Maggie Rose Pelella, Judith Miller, Alison Russell, Alison Hulick, Michaela Leuzzi, Ani Nenkova, <span style="color:#063852">Wei Lai</span>, Jennifer Uzokwe, Kevin Walker, Christopher Cieri, James Fiumara, Juhi Pandey, Christopher Chatham, Robert Schultz, Mark Liberman, Julia Parish-Morris. Children with ASD Describe Pictures Differently Than Matched Non-Autistic Peers. Annual Meeting of the International Society for Autism Research (INSAR). Austin, Texas. (poster)</li>
         <li align="left" > Aini Li, <span style="color:#063852">Wei Lai</span> and Jianjing Kuang. How do listeners identify creak? The case of Mandarin.
        The 11th International Conference on Speech Prosody. Lisbon, Portugal. (talk)</li>
         <li align="left" > Aini Li, <span style="color:#063852">Wei Lai</span> and Jianjing Kuang. How do listeners identify creak? The effects of tone, pitch range, prosodic position and creak locality in Mandarin. The 96th Annual Meeting of the Linguistic Society of America. Washington, DC. (poster) </li>
     </ul></p>
      
      <h4 align="left" id="flexibility" style="font-family: sans-serif; color:#063852; font-size: 20px; margin-top: 30px">2020</h4>
            <p> <ul>
               <li align="left" > Villanova University. Coping with habitual and situational speech variability in speech perception. Psychological and Brain Sciences. April 30. (invited talk).</li>
                <li align="left" >The Chinese University of Hong Kong. A psycholinguitic study on Chinese tone variation}. Department of Chinese Language and Literature. April 3. (invited talk).</li>
                 <li align="left" >Saarland University. Encoding and decoding information through structured speech variability. Department of Language Science and Technology. Jan 21. (invited talk).</li>
                  <li align="left" ><span style="color:#063852">Wei Lai</span> and Aini  Li. Integrating  phonetic and phonological  aspects  of  Mandarin 3rd tonesandhi in the auditory disambiguation of short and long sentences.17th Conference on Laboratory Phonology.  Vancouver, Canada. (poster)</li>
                  <li align="left" > <span style="color:#063852">Wei Lai</span> and Aini Li. The integration  of Mandarin third tone sandhi in auditory sentence disambiguation.Conference on Human Sentence Processing (CUNY). Boston, MA. (poster)</li>
                </ul></p>
        
    <h4 align="left" id="flexibility" style="font-family: sans-serif; color:#063852; font-size: 20px; margin-top: 30px">2019</h4>
            <p><ul>
        <li align="left" ><span style="color:#063852">Wei Lai</span>, Mark Liberman and Qianxin He. Compensation for <i>F<sub>0</sub></i> variation with vocal effort and vowel height in Cantonese tone perception <i>Internaltional Congress of Phonetic Sciences ICPhS 2019</i>, Melboulne, Australia. 2019. (talk)</li>
        <li align="left" >Meredith Tamminga, Lacey Wade and <span style="color:#063852">Wei Lai</span>. The search  for  predictors of individualdifferences in VOT imitation.<i>The 48th New Ways of Analyzing Variation</i>. Eugene, Oregon. (talk)</li>
        <li align="left" ><span style="color:#063852">Wei Lai</span>, Peter Racz amd Gareth Roberts. Unexpectedness makes a sociolinguistic variant easier to learn: An alien-language-learning experiment. <i>The 41st Annual Meeting of the Cognitive Science Society</i>, Montreal, Canada. 2019. (talk)</li>
        <li align="left" ><span style="color:#063852">Wei Lai</span> and Meredith Tamminga. Individual differences in simultaneous compensation for coarticu-latory and lexical cues. <i>The 5th Workshop of Sound Change</i>, UC Davis, CA. (talk)</li>
        <li align="left" ><span style="color:#063852">Wei Lai</span>, Peter Racz and Gareth Roberts. Experience with a linguistic variant affects the acquisition of its sociolinguistic meaning: An alien-language-learning experiment. <i>93th Linguistic Society of America</i>, New York City, NY. (talk)</li>
     </ul></p>
      

    <h4 align="left" id="flexibility" style="font-family: sans-serif; color:#063852; font-size: 20px; margin-top: 30px">2018</h4>
        <p> <ul>
        <li align="left" ><span style="color:#063852">Wei Lai</span>, Peter Racz and Gareth Roberts. Prior experience with a linguistic variant affects the acquisition of its social meaning: An experimental simulation using alien language learning. <i>New Ways of Analyzing Variation 47</i>, New York City, NY. (talk) </li>
        <li align="left" ><span style="color:#063852">Wei Lai</span>. Gender stereotypes affect the perception of tone and pitch. <i>New Ways of Analyzing Variation 47</i>, New York City, NY. (talk)</li>
        <li align="left" ><span style="color:#063852">Wei Lai</span>. Voice gender effect on tone categorization and pitch perception. <i>6th International Symposium on Tonal Aspects of Languages</i>. Berlin, German. (talk)</li>
        <li align="left" ><span style="color:#063852">Wei Lai</span> and Mark Liberman. A rhythmic constraint on prosodic boundaries in Mandarin Chinese based on corpora of silent reading and speech perception. <i>92th Linguistic Society of America</i>, Salt Lake City, UT. (talk) </li>
        <li align="left" ><span style="color:#063852">Wei Lai</span>. Auditory-visual integration of talker gender in Cantonese tone perception. <i>92th Linguistic Society of America</i>, Salt Lake City, UT. (talk)</li>
        <li align="left" >Meredith Tamminga, Lacey Wade and <span style="color:#063852">Wei Lai</span>. Stability and variability in phonetic flexibility. <i>92th Linguistic Society of America</i>, Salt Lake City, UT. (talk)</li>
      </ul></p>

    <h4 align="left" id="flexibility" style="font-family: sans-serif; color:#063852; font-size: 20px; margin-top: 30px">2016</h4>
         <p> <ul>
        <li align="left" ><span style="color:#063852">Wei Lai</span>, Jiahong Yuan, Ya Li, Xiaoying Xu and Mark Liberman. The rhythmic constraint on prosodic boundaries in mandarin Chinese Based on corpora of silent reading and speech perception. <i>Interspeech 2016</i>. San Francisco, CA. (talk) (best student award)</li>
        <li align="left" ><span style="color:#063852">Wei Lai</span>, Mark Liberman, Jiahong Yuan and Xiaoying Xu. Prosodic strength intrinsic to lexical items: A corpus study on tone reduction in Tone4+Tone4 words in Mandarin Chinese. <i>10th Chinese Spoken Language Processing (ISCSLP)</i>. Tianjin, China. (poster)</li>
        <li align="left" ><span style="color:#063852">Wei Lai</span> and Laura Dilley (2016). Cross-linguistic generalization of the distal rate effect: Speech rate in context affects whether listeners hear a function word in Chinese Mandarin. <i>8th Speech Prosody</i>. Boston, MA. (poster)</li>
       <li align="left" ><span style="color:#063852">Wei Lai</span> and Jianjing Kuang (2016). Prosodic grouping in Chinese trisyllabic structules by multiple cues -- coarticulation, tone sandhi and consonant lenition. <i> Tonal Aspects of Languages 2016</i>. Buffalo, NY. (poster)</li>
        </ul></p>
   
   <h4 align="left" id="flexibility" style="font-family: sans-serif; color:#063852; font-size: 20px; margin-top: 30px">2014</h4>
        <p><ul>
        <li align="left" ><span style="color:#063852">Wei Lai</span>, Xiaoying Xu, Ya Li, Hao Che, Shanfeng Liu, and Jianhua Tao (2014). Phonological influences on the realization of final lowering evidence from dialogue Chinese Mandarin. <i>17th Co-ordination and Standardization of Speech Databases and Assessment Techniques (COCOSDA) </i>. Phuket, Thailand. (talk)</li>
       <li align="left" ><span style="color:#063852">Wei Lai</span>, Ya Li, Che, H., Shanfeng Liu, Jianhua Tao, and Xiaoying Xu. Final lowering effect in questions and statements of Chinese Mandarin based on a large-scale natulal dialogue corpus Analysis. <i>7th Speech Prosody</i>. Dublin, Ireland.  (poster)</li>
        <li align="left" >Ya Li, Jianhua Tao, Keikichi Hirose, <span style="color:#063852">Wei Lai</span> and Xiaoying Xu. Hierarchical stress generation with Fujisaki model in expressive speech synthesis. <i>7th Speech Prosody</i>. Dublin, Ireland. (poster)</li>
      </ul></p>
  </div>
</section>


 <section id="teaching"  class="site-section section-services overlay text-center">
    <div align="center" class="container">
          <h3 style=" color:#68829E" class="text-center">Teaching</h3>
          <img  src="assets/img/lines.svg" class="img-lines" alt="lines">
          <p></p>
          <img src="assets/img/teaching.jpg" style="max-width: 80%;vertical-align: baseline;">
          <p  style="color:#4D648D; f align-self: right">Teaching on [t/d] deletion. Photo credit to Desen Lin.<br></p>
          <p></p>
       <table style="line-height:30px; max-width: 90%; margin-left: 5%; margin-right: 5%;margin-bottom: 0%;">
      <tr><td colspan="2" style="color:#063852;">Experience</td></tr>
       <tr>
        <td style=" text-align:left; width: 9em"><i>Summer 2020</i></td>
        <td>Instructor of LING120 - Introduction to Sociolinguistics. </td>
      </tr>
      <tr>
        <td style=" text-align:left; width: 9em"><i>Spring 2018</i></td>
        <td>TA of LING210 - Introduction to Language Change.</td>
      </tr>
      <tr>
        <td style=" text-align:left; "><i>Fall 2017</i></td>
        <td> Recitation TA of LING001 - Introduction to Linguistics. Recitation.</td>
      </tr>
      <tr>
        <td style=" text-align:left;"><i>Spring 2017</i></td>
        <td> Recitation TA of LING001 - Introduction to Linguistics.</td>
      </tr>
      <tr>
        <td><br></td>
        <td><br></td>
      </tr>
      <tr><td colspan="2" style="color:#063852;">Certificate</td></tr>
      <tr>
        <td style=" text-align:left;"><i>December 2020</i></td>
        <td>UPenn CTL (Center for Teaching & Learning) Teaching Certificate</td>
      </tr>
      <tr>
        <td style=" text-align:left; "><i>August 2016</i></td>
        <td>UPenn Language Program for International Teaching Assistants</td>
      </tr>
    </table>
  </div><!-- /.hero -->
</section>
        <section id="resources" class="site-section section-counters text-center">
            <div class="container">
                <div class="col-md-12">
                    <h4 style="color:white" >Resources</h4>
                    <p style="color:white">
                        <ur>
                            <li style="color:white" align="left">A praat script for extracting vowel formants: 
                            <a href="https://github.com/weilaiPhonetics/PraatScripts/blob/main/vowel_formant.praat"  style="color:white">https://github.com/weilaiPhonetics/PraatScripts/blob/main/vowel_formant.praat</a>.</li>
                            <li style="color:white" align="left">A praat script for extracting duration: <a href="https://github.com/weilaiPhonetics/PraatScripts/blob/main/duration.praat"  style="color:white">https://github.com/weilaiPhonetics/PraatScripts/blob/main/duration.praat</a>.</li>
                            <li style="color:white" align="left">A web tutorial that explains how the previous Praat script is constructed: <a href="https://sites.google.com/view/praattutorial/home"  style="color:white">https://sites.google.com/view/praattutorial/home</a>. It also walks you through sound annotation with Praat TextGrid step by step.</li>
                        </ur>
                    </p>
                </div>
            </div>
        </section><!-- /.section-counters -->
    </main><!-- /#main -->
    <footer id="colophon" class="site-footer">
        <div class="container">
            <div class="row">
                <div class="col-sm-4 col-xs-12">
                    <a class="icon facebook-bg" href="https://www.facebook.com/wei.lai.75470/"><i class="icon-facebook"></i></a>
                    <a class="icon twitter-bg" href="https://twitter.com/WeiLai93221257"><i class="icon-twitter"></i></a>
                    <a class="icon gplus-bg" href="https://www.linkedin.com/in/wei-lai-83a33696/?locale=en_US"><i class="icon-linkedin"></i></a>
                    <a class="icon linkedin-bg" href="https://scholar.google.com/citations?user=n8apJ-cAAAAJ&hl=en&authuser=1"><i class="icon-gplus"></i></a>
                </div>
                <div class="col-sm-4 col-sm-offset-0 col-xs-6 col-xs-offset-3"><p class="copyright"> Last updated on Oct. 30, 2020. </p></div>
                <div class="col-sm-4 col-xs-3">
                    <div class="text-right page-scroll">
                         <h1 class="modal-title">Wei Lai</h1>
                    </div>
                </div>
            </div>
        </div>
    </footer><!-- /#footer -->

    <!-- Modals -->
    <div id="portfolioItem2" class="modal fade" role="dialog">
      <div class="modal-dialog">
        <div class="modal-content">
         

        </div><!-- /.modal-content -->
      </div><!-- /.modal-dialog -->
    </div><!-- /.modal -->
    <div id="portfolioItem1" class="modal fade" role="dialog">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="modal-body">
          </div>
        </div><!-- /.modal-content -->
      </div><!-- /.modal-dialog -->
    </div><!-- /.modal -->
    <div id="portfolioItem4" class="modal fade" role="dialog">
      <div class="modal-dialog">
        <div class="modal-content">
        </div><!-- /.modal-content -->
      </div><!-- /.modal-dialog -->
    </div><!-- /.modal -->

    <div id="portfolioItem3" class="modal fade" role="dialog">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="modal-body">
          </div>
        </div><!-- /.modal-content -->
      </div><!-- /.modal-dialog -->
    </div><!-- /.modal -->

    <div id="portfolioItem5" class="modal fade" role="dialog">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="modal-body">
          </div>
        </div><!-- /.modal-content -->
      </div><!-- /.modal-dialog -->
    </div><!-- /.modal -->

    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
    <script src="assets/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.4.1/jquery.easing.min.js"></script>
    <script src="assets/js/skrollr.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/bootstrap-progressbar/0.9.0/bootstrap-progressbar.min.js"></script>
    <script src="assets/js/jquery.countTo.min.js"></script>
    <script src="assets/js/script.js"></script>
  
</body>
</html>
